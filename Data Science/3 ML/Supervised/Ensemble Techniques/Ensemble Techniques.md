-----------------------
Tags: #ml #ensemble_tech 
Date Created:  2023-06-17, @ 12:11

---
>[!info] Keywords
>*

Ensemble techniques in Machine Learning involve **combining multiple models to create a more accurate and robust predictor**. The idea is that by aggregating the predictions of multiple models, the ensemble can often outperform any individual model. Ensemble techniques are used when we want to improve prediction accuracy, reduce 
[[Overfitting]] , and handle complex or uncertain data.

Here are a few examples of ensemble techniques:

1. **[[Random Forest]]**: As explained earlier, Random Forest is an ensemble technique that combines multiple decision trees to make predictions. It is used for classification and regression tasks, where each tree in the forest contributes to the final prediction.
    
2. **[[Boosting]]**: Boosting is another popular ensemble technique. It works by training models sequentially, where each subsequent model focuses on improving the weaknesses of the previous model. Examples of boosting algorithms include AdaBoost (Adaptive Boosting) and Gradient Boosting.
    
3. **[[Bagging]]**: Bagging, short for **bootstrap aggregating**, involves training multiple models on different subsets of the training data. These models are then combined to make predictions. The famous example of bagging is the **Random Forest** algorithm.
    
4. **[[Voting]]**: Voting is a simple ensemble technique where multiple models make predictions, and the final prediction is determined based on majority voting. There are different types of voting, such as hard voting (majority of votes) and soft voting (weighted average of probabilities).
    
5. **[[Stacking]]**: Stacking combines the predictions of multiple models by training another model, called a meta-learner, on their outputs. The meta-learner learns to make predictions based on the predictions of the individual models. Stacking can be more powerful but also more complex than other ensemble techniques.












>[!summary] 
>1. ...
>2. ...

----
>[!cite]
> [[]]
> []()
