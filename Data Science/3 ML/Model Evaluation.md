------------------------- 
Tags: #ml 
Date Created:  2023-06-02, @ 09:31

---
>[!info] Keywords
>*
### Some Terms Used: 

[[Overfitting]] is a common problem in machine learning where a model performs well on the training data but fails to generalize well to unseen data. It occurs when a model learns the noise or random fluctuations in the training data instead of the underlying patterns or relationships. Essentially, the model becomes too complex and captures the specific examples and variations in the training data, making it less effective in making accurate predictions on new, unseen data.

Other related concepts in machine learning include:

1. [[Underfitting]]: Underfitting occurs when a model is too simple or lacks the capacity to capture the underlying patterns in the data. It results in poor performance both on the training data and unseen data. Underfit models may oversimplify the relationships and fail to learn important features.
    
2. [[Bias-Variance Tradeoff]]: The bias-variance tradeoff refers to the relationship between the bias (error due to wrong assumptions) and variance (error due to sensitivity to variations in the training data) of a model. A high-bias model is likely to underfit, while a high-variance model is prone to overfitting. The goal is to find a balance between bias and variance to achieve optimal model performance.
    
3. [[Regularization]]: Regularization is a technique used to prevent overfitting by adding a penalty term to the model's objective function. It helps to constrain the model's complexity and discourage it from learning noise in the training data. Regularization techniques, such as L1 regularization (Lasso) and L2 regularization (Ridge), can shrink the model's coefficients or weights.
    
4. [[Cross-Validation]]: Cross-validation is a technique used to assess the generalization performance of a model. It involves splitting the available data into multiple subsets, typically a training set and a validation set, to evaluate the model's performance on unseen data. Cross-validation helps to estimate how well the model will perform on new data and can be used for model selection and hyperparameter tuning.
    
5. Training Set, Validation Set, and Test Set: These are distinct subsets of the available data used for different purposes. The training set is used to train the model, the validation set is used to tune model hyperparameters and assess performance during training, and the test set is used to evaluate the final model's performance on unseen data. Separating the data into these subsets helps assess and prevent overfitting.
    
It's important to understand these concepts to build robust and generalizable machine learning models and to take appropriate steps to avoid overfitting or underfitting, such as regularization, cross-validation, and proper data splitting.

### Model Evaluation:


>[!summary] 
>1. ...
>2. ...

----
>[!cite]
> [[]]
> []()
